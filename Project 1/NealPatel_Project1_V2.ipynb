{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class 7- Starter code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, metrics\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Create sample data and fit a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'x': range(1000), 'y': range(1000)})\n",
    "# NOTE: Whenever you make changes to dataframes and want to keep the original\n",
    "# make sure you do a deep copy\n",
    "biased_df  = df.copy(deep=True) \n",
    "biased_df.loc[:20, 'x'] = 1 # create a bias with both columns\n",
    "biased_df.loc[:20, 'y'] = 1\n",
    "\n",
    "def append_jitter(series):\n",
    "    # adds uniform random variable to the input series\n",
    "    jitter = np.random.random_sample(size=1000)\n",
    "    return series + jitter\n",
    "\n",
    "df['x'] = append_jitter(df.x)\n",
    "df['y'] = append_jitter(df.y)\n",
    "\n",
    "biased_df['x'] = append_jitter(biased_df.x)\n",
    "biased_df['y'] = append_jitter(biased_df.y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.168750573078\n"
     ]
    }
   ],
   "source": [
    "## fit\n",
    "lm = linear_model.LinearRegression().fit(df[['x']], df['y'])\n",
    "print metrics.mean_squared_error(df['y'], lm.predict(df[['x']]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.166725709491\n"
     ]
    }
   ],
   "source": [
    "## biased fit\n",
    "lm = linear_model.LinearRegression().fit(biased_df[['x']], biased_df['y'])\n",
    "print metrics.mean_squared_error(biased_df['y'], lm.predict(biased_df[['x']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11ab63810>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEACAYAAACpoOGTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b2c1690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEACAYAAACpoOGTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a9206d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(lm.predict(biased_df[['x']])-lm.predict(biased_df[['y']])).plot(kind=\"density\")\n",
    "pd.DataFrame(lm.predict(df[['x']])-lm.predict(df[['y']])).plot(kind=\"density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question - try to look at the distribution of the residuals for both biased_df and df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "#### Intro to cross validation with bike share data from last time. We will be modeling casual ridership. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "wd = '../../assets/dataset/'\n",
    "bikeshare = pd.read_csv(wd + 'bikeshare.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Create dummy variables and set outcome (dependent) variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather = pd.get_dummies(bikeshare.weathersit, prefix='weather')\n",
    "modeldata = bikeshare[['temp', 'hum']].join(weather[['weather_1', 'weather_2', 'weather_3']])\n",
    "y = pd.DataFrame(bikeshare.casual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a cross valiation with 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17379, 5)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = cross_validation.KFold(len(modeldata), n_folds=5, shuffle=True)\n",
    "modeldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([    0,     1,     3, ..., 17376, 17377, 17378]), array([    2,    10,    20, ..., 17364, 17367, 17372]))\n",
      "(13903,) (3476,)\n",
      "(array([    0,     1,     2, ..., 17376, 17377, 17378]), array([    6,     7,    13, ..., 17366, 17368, 17375]))\n",
      "(13903,) (3476,)\n",
      "(array([    2,     3,     4, ..., 17375, 17376, 17377]), array([    0,     1,    25, ..., 17369, 17373, 17378]))\n",
      "(13903,) (3476,)\n",
      "(array([    0,     1,     2, ..., 17375, 17376, 17378]), array([    4,     8,    12, ..., 17359, 17370, 17377]))\n",
      "(13903,) (3476,)\n",
      "(array([    0,     1,     2, ..., 17375, 17377, 17378]), array([    3,     5,     9, ..., 17371, 17374, 17376]))\n",
      "(13904,) (3475,)\n"
     ]
    }
   ],
   "source": [
    "# kf basically contains 5 different test train sets of 80% and 20% split\n",
    "for a in kf:\n",
    "    print a\n",
    "    print a[0].shape , a[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~ CROSS VALIDATION each fold ~~~~\n",
      "Model 1\n",
      "MSE: 1596.71181554\n",
      "R2: 0.315687927282\n",
      "Model 2\n",
      "MSE: 1779.41948552\n",
      "R2: 0.297364280691\n",
      "Model 3\n",
      "MSE: 1609.52812215\n",
      "R2: 0.315647354912\n",
      "Model 4\n",
      "MSE: 1768.56961786\n",
      "R2: 0.310517120277\n",
      "Model 5\n",
      "MSE: 1612.52205656\n",
      "R2: 0.318213490799\n",
      "~~~~ SUMMARY OF CROSS VALIDATION ~~~~\n",
      "Mean of MSE for all folds: 1673.35021953\n",
      "Mean of R2 for all folds: 0.311486034792\n"
     ]
    }
   ],
   "source": [
    "mse_values = []\n",
    "scores = []\n",
    "n= 0\n",
    "print \"~~~~ CROSS VALIDATION each fold ~~~~\"\n",
    "for train_index, test_index in kf:\n",
    "    lm = linear_model.LinearRegression().fit(modeldata.iloc[train_index], y.iloc[train_index])\n",
    "    mse_values.append(metrics.mean_squared_error(y.iloc[test_index], lm.predict(modeldata.iloc[test_index])))\n",
    "    scores.append(lm.score(modeldata.iloc[test_index], y.iloc[test_index]))\n",
    "    n+=1\n",
    "    print 'Model', n\n",
    "    print 'MSE:', mse_values[n-1]\n",
    "    print 'R2:', scores[n-1]\n",
    "\n",
    "\n",
    "print \"~~~~ SUMMARY OF CROSS VALIDATION ~~~~\"\n",
    "print 'Mean of MSE for all folds:', np.mean(mse_values)\n",
    "print 'Mean of R2 for all folds:', np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~ Single Model ~~~~\n",
      "MSE of single model: 1672.58110765\n",
      "R2:  0.311934605989\n"
     ]
    }
   ],
   "source": [
    "lm = linear_model.LinearRegression().fit(modeldata, y)\n",
    "print \"~~~~ Single Model ~~~~\"\n",
    "print 'MSE of single model:', metrics.mean_squared_error(y, lm.predict(modeldata))\n",
    "print 'R2: ', lm.score(modeldata, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check\n",
    "While the cross validated approach here generated more overall error, which of the two approaches would predict new data more accurately: the single model or the cross validated, averaged one? Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are ways to improve our model with regularization. \n",
    "Let's check out the effects on MSE and R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>weather_1</th>\n",
       "      <th>weather_2</th>\n",
       "      <th>weather_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.069881</td>\n",
       "      <td>0.101044</td>\n",
       "      <td>-0.069657</td>\n",
       "      <td>-0.062406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hum</th>\n",
       "      <td>-0.069881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.383425</td>\n",
       "      <td>0.220758</td>\n",
       "      <td>0.309737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_1</th>\n",
       "      <td>0.101044</td>\n",
       "      <td>-0.383425</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.822961</td>\n",
       "      <td>-0.412414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_2</th>\n",
       "      <td>-0.069657</td>\n",
       "      <td>0.220758</td>\n",
       "      <td>-0.822961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.177417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_3</th>\n",
       "      <td>-0.062406</td>\n",
       "      <td>0.309737</td>\n",
       "      <td>-0.412414</td>\n",
       "      <td>-0.177417</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               temp       hum  weather_1  weather_2  weather_3\n",
       "temp       1.000000 -0.069881   0.101044  -0.069657  -0.062406\n",
       "hum       -0.069881  1.000000  -0.383425   0.220758   0.309737\n",
       "weather_1  0.101044 -0.383425   1.000000  -0.822961  -0.412414\n",
       "weather_2 -0.069657  0.220758  -0.822961   1.000000  -0.177417\n",
       "weather_3 -0.062406  0.309737  -0.412414  -0.177417   1.000000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldata.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~ OLS ~~~\n",
      "OLS MSE:  1672.58110765\n",
      "OLS R2: 0.311934605989\n",
      "[[ 112.68901765  -84.01121684  -24.68489063  -21.00314494  -21.71893628]]\n",
      "~~~ Lasso ~~~\n",
      "Lasso MSE:  1725.41581608\n",
      "Lasso R2: 0.290199495922\n",
      "[ 86.81079432 -55.76414394   0.          -0.          -0.        ]\n",
      "~~~ Ridge ~~~\n",
      "Ridge MSE:  1672.60490113\n",
      "Ridge R2: 0.311924817843\n",
      "[[ 112.50129738  -83.84805622  -13.38214934   -9.72671278  -10.46162477]]\n"
     ]
    }
   ],
   "source": [
    "lm = linear_model.LinearRegression().fit(modeldata, y)\n",
    "print \"~~~ OLS ~~~\"\n",
    "print 'OLS MSE: ', metrics.mean_squared_error(y, lm.predict(modeldata))\n",
    "print 'OLS R2:', lm.score(modeldata, y)\n",
    "print lm.coef_\n",
    "\n",
    "lm = linear_model.Lasso().fit(modeldata, y)\n",
    "print \"~~~ Lasso ~~~\"\n",
    "print 'Lasso MSE: ', metrics.mean_squared_error(y, lm.predict(modeldata))\n",
    "print 'Lasso R2:', lm.score(modeldata, y)\n",
    "print lm.coef_\n",
    "\n",
    "lm = linear_model.Ridge().fit(modeldata, y)\n",
    "print \"~~~ Ridge ~~~\"\n",
    "print 'Ridge MSE: ', metrics.mean_squared_error(y, lm.predict(modeldata))\n",
    "print 'Ridge R2:', lm.score(modeldata, y)\n",
    "print lm.coef_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figuring out the alphas can be done by \"hand\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 1e-10\n",
      "[[ 112.68901765  -84.01121684  -24.68489063  -21.00314493  -21.71893628]]\n",
      "1672.58110765\n",
      "Alpha: 1e-09\n",
      "[[ 112.68901765  -84.01121684  -24.68489061  -21.00314491  -21.71893626]]\n",
      "1672.58110765\n",
      "Alpha: 1e-08\n",
      "[[ 112.68901765  -84.01121684  -24.6848904   -21.00314471  -21.71893606]]\n",
      "1672.58110765\n",
      "Alpha: 1e-07\n",
      "[[ 112.68901763  -84.01121682  -24.68488837  -21.00314268  -21.71893403]]\n",
      "1672.58110765\n",
      "Alpha: 1e-06\n",
      "[[ 112.68901745  -84.01121667  -24.68486804  -21.00312237  -21.71891373]]\n",
      "1672.58110765\n",
      "Alpha: 1e-05\n",
      "[[ 112.68901562  -84.01121509  -24.68466472  -21.00291929  -21.71871079]]\n",
      "1672.58110765\n",
      "Alpha: 0.0001\n",
      "[[ 112.68899732  -84.01119938  -24.68263174  -21.00088873  -21.71668161]]\n",
      "1672.58110765\n",
      "Alpha: 0.001\n",
      "[[ 112.68881437  -84.01104228  -24.66232204  -20.98060316  -21.69640993]]\n",
      "1672.58110774\n",
      "Alpha: 0.01\n",
      "[[ 112.68698753  -84.00947323  -24.46121539  -20.77973778  -21.49568404]]\n",
      "1672.58111645\n",
      "Alpha: 0.1\n",
      "[[ 112.66896732  -83.99396383  -22.63109556  -18.95202277  -19.66942371]]\n",
      "1672.58185208\n",
      "Alpha: 1.0\n",
      "[[ 112.50129738  -83.84805622  -13.38214934   -9.72671278  -10.46162477]]\n",
      "1672.60490113\n",
      "Alpha: 10.0\n",
      "[[ 110.96062533  -82.49604961   -3.94431741   -0.51765034   -1.45024412]]\n",
      "1672.83347262\n",
      "Alpha: 100.0\n",
      "[[ 97.69060562 -71.17602377  -0.31585194   1.18284675  -1.33281591]]\n",
      "1686.31830362\n",
      "Alpha: 1000.0\n",
      "[[ 44.59923075 -30.85843772   5.07876321   0.05369643  -5.107457  ]]\n",
      "1937.81576044\n",
      "Alpha: 10000.0\n",
      "[[ 7.03007064 -5.07733082  3.29039029 -1.2136063  -2.06842808]]\n",
      "2314.83675678\n",
      "Alpha: 100000.0\n",
      "[[ 0.75195708 -0.56490872  0.52067881 -0.25075496 -0.26895254]]\n",
      "2415.77806566\n",
      "Alpha: 1000000.0\n",
      "[[ 0.07576571 -0.05727511  0.05520142 -0.0273591  -0.02774349]]\n",
      "2429.28026459\n",
      "Alpha: 10000000.0\n",
      "[[ 0.00758239 -0.00573569  0.0055535  -0.00276043 -0.00278317]]\n",
      "2430.68891798\n",
      "Alpha: 100000000.0\n",
      "[[ 0.0007583  -0.00057365  0.00055569 -0.00027629 -0.00027841]]\n",
      "2430.83041212\n",
      "Alpha: 1000000000.0\n",
      "[[  7.58303020e-05  -5.73659720e-05   5.55719458e-05  -2.76314619e-05\n",
      "   -2.78414555e-05]]\n",
      "2430.84456787\n",
      "Alpha: 10000000000.0\n",
      "[[  7.58303603e-06  -5.73660542e-06   5.55722818e-06  -2.76317091e-06\n",
      "   -2.78415441e-06]]\n",
      "2430.84598351\n"
     ]
    }
   ],
   "source": [
    "alphas = np.logspace(-10, 10, 21)\n",
    "for a in alphas:\n",
    "    print 'Alpha:', a\n",
    "    lm = linear_model.Ridge(alpha=a)\n",
    "    lm.fit(modeldata, y)\n",
    "    print lm.coef_\n",
    "    print metrics.mean_squared_error(y, lm.predict(modeldata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or we can use grid search to make this faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'normalize': [True, False], 'alpha': array([  1.00000e-10,   1.00000e-09,   1.00000e-08,   1.00000e-07,\n",
       "         1.00000e-06,   1.00000e-05,   1.00000e-04,   1.00000e-03,\n",
       "         1.00000e-02,   1.00000e-01,   1.00000e+00,   1.00000e+01,\n",
       "         1.00000e+02,   1.00000e+03,   1.00000e+04,   1.00000e+05,\n",
       "         1.00000e+06,   1.00000e+07,   1.00000e+08,   1.00000e+09,\n",
       "         1.00000e+10]), 'fit_intercept': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='mean_squared_error',\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import grid_search\n",
    "\n",
    "alphas = np.logspace(-10, 10, 21)\n",
    "gs = grid_search.GridSearchCV(\n",
    "    estimator=linear_model.Lasso(),\n",
    "    param_grid={'alpha': alphas,'fit_intercept':[True,False],'normalize':[True,False]},\n",
    "    scoring='mean_squared_error',cv=10)\n",
    "\n",
    "gs.fit(modeldata, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1742.92316008\n"
     ]
    }
   ],
   "source": [
    "print gs.best_score_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### mean squared error here comes in negative, so let's make it positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1742.92316008\n"
     ]
    }
   ],
   "source": [
    "print -gs.best_score_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### explains which grid_search setup worked best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'temp', u'hum', u'weather_1', u'weather_2', u'weather_3'], dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeldata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.10000000000000001, copy_X=True, fit_intercept=True,\n",
       "   max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "   random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 109.93593998  -80.45002088   -1.82328187    0.77974702   -0.        ]\n"
     ]
    }
   ],
   "source": [
    "print gs.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### shows all the grid pairings and their performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mean: -1743.92970, std: 1051.57802, params: {'normalize': True, 'alpha': 1e-10, 'fit_intercept': True}, mean: -1743.92970, std: 1051.57802, params: {'normalize': False, 'alpha': 1e-10, 'fit_intercept': True}, mean: -1744.68267, std: 1051.62193, params: {'normalize': True, 'alpha': 1e-10, 'fit_intercept': False}, mean: -1744.68267, std: 1051.62193, params: {'normalize': False, 'alpha': 1e-10, 'fit_intercept': False}, mean: -1743.92970, std: 1051.57802, params: {'normalize': True, 'alpha': 1.0000000000000001e-09, 'fit_intercept': True}, mean: -1743.92970, std: 1051.57802, params: {'normalize': False, 'alpha': 1.0000000000000001e-09, 'fit_intercept': True}, mean: -1744.68267, std: 1051.62193, params: {'normalize': True, 'alpha': 1.0000000000000001e-09, 'fit_intercept': False}, mean: -1744.68267, std: 1051.62193, params: {'normalize': False, 'alpha': 1.0000000000000001e-09, 'fit_intercept': False}, mean: -1743.92970, std: 1051.57802, params: {'normalize': True, 'alpha': 1e-08, 'fit_intercept': True}, mean: -1743.92970, std: 1051.57802, params: {'normalize': False, 'alpha': 1e-08, 'fit_intercept': True}, mean: -1744.68267, std: 1051.62193, params: {'normalize': True, 'alpha': 1e-08, 'fit_intercept': False}, mean: -1744.68267, std: 1051.62193, params: {'normalize': False, 'alpha': 1e-08, 'fit_intercept': False}, mean: -1743.92970, std: 1051.57807, params: {'normalize': True, 'alpha': 9.9999999999999995e-08, 'fit_intercept': True}, mean: -1743.92970, std: 1051.57802, params: {'normalize': False, 'alpha': 9.9999999999999995e-08, 'fit_intercept': True}, mean: -1744.68267, std: 1051.62193, params: {'normalize': True, 'alpha': 9.9999999999999995e-08, 'fit_intercept': False}, mean: -1744.68267, std: 1051.62193, params: {'normalize': False, 'alpha': 9.9999999999999995e-08, 'fit_intercept': False}, mean: -1743.92962, std: 1051.57849, params: {'normalize': True, 'alpha': 9.9999999999999995e-07, 'fit_intercept': True}, mean: -1743.92970, std: 1051.57802, params: {'normalize': False, 'alpha': 9.9999999999999995e-07, 'fit_intercept': True}, mean: -1744.68267, std: 1051.62193, params: {'normalize': True, 'alpha': 9.9999999999999995e-07, 'fit_intercept': False}, mean: -1744.68267, std: 1051.62193, params: {'normalize': False, 'alpha': 9.9999999999999995e-07, 'fit_intercept': False}, mean: -1743.92918, std: 1051.58241, params: {'normalize': True, 'alpha': 1.0000000000000001e-05, 'fit_intercept': True}, mean: -1743.92970, std: 1051.57802, params: {'normalize': False, 'alpha': 1.0000000000000001e-05, 'fit_intercept': True}, mean: -1744.68267, std: 1051.62194, params: {'normalize': True, 'alpha': 1.0000000000000001e-05, 'fit_intercept': False}, mean: -1744.68267, std: 1051.62194, params: {'normalize': False, 'alpha': 1.0000000000000001e-05, 'fit_intercept': False}, mean: -1743.93341, std: 1051.61022, params: {'normalize': True, 'alpha': 0.0001, 'fit_intercept': True}, mean: -1743.92968, std: 1051.57808, params: {'normalize': False, 'alpha': 0.0001, 'fit_intercept': True}, mean: -1744.68264, std: 1051.62205, params: {'normalize': True, 'alpha': 0.0001, 'fit_intercept': False}, mean: -1744.68264, std: 1051.62205, params: {'normalize': False, 'alpha': 0.0001, 'fit_intercept': False}, mean: -1743.89743, std: 1051.91005, params: {'normalize': True, 'alpha': 0.001, 'fit_intercept': True}, mean: -1743.92951, std: 1051.57864, params: {'normalize': False, 'alpha': 0.001, 'fit_intercept': True}, mean: -1744.68234, std: 1051.62308, params: {'normalize': True, 'alpha': 0.001, 'fit_intercept': False}, mean: -1744.68234, std: 1051.62308, params: {'normalize': False, 'alpha': 0.001, 'fit_intercept': False}, mean: -1743.15883, std: 1055.14801, params: {'normalize': True, 'alpha': 0.01, 'fit_intercept': True}, mean: -1743.92784, std: 1051.58418, params: {'normalize': False, 'alpha': 0.01, 'fit_intercept': True}, mean: -1744.67940, std: 1051.63343, params: {'normalize': True, 'alpha': 0.01, 'fit_intercept': False}, mean: -1744.67940, std: 1051.63343, params: {'normalize': False, 'alpha': 0.01, 'fit_intercept': False}, mean: -1742.54355, std: 1085.09595, params: {'normalize': True, 'alpha': 0.10000000000000001, 'fit_intercept': True}, mean: -1743.91380, std: 1051.63647, params: {'normalize': False, 'alpha': 0.10000000000000001, 'fit_intercept': True}, mean: -1744.65006, std: 1051.73687, params: {'normalize': True, 'alpha': 0.10000000000000001, 'fit_intercept': False}, mean: -1744.65006, std: 1051.73687, params: {'normalize': False, 'alpha': 0.10000000000000001, 'fit_intercept': False}, mean: -1899.23013, std: 1237.53176, params: {'normalize': True, 'alpha': 1.0, 'fit_intercept': True}, mean: -1743.77710, std: 1052.14163, params: {'normalize': False, 'alpha': 1.0, 'fit_intercept': True}, mean: -1744.36184, std: 1052.76655, params: {'normalize': True, 'alpha': 1.0, 'fit_intercept': False}, mean: -1744.36184, std: 1052.76655, params: {'normalize': False, 'alpha': 1.0, 'fit_intercept': False}, mean: -2343.93783, std: 1388.42342, params: {'normalize': True, 'alpha': 10.0, 'fit_intercept': True}, mean: -1742.34760, std: 1057.35486, params: {'normalize': False, 'alpha': 10.0, 'fit_intercept': True}, mean: -1741.96025, std: 1062.62606, params: {'normalize': True, 'alpha': 10.0, 'fit_intercept': False}, mean: -1741.96025, std: 1062.62606, params: {'normalize': False, 'alpha': 10.0, 'fit_intercept': False}, mean: -2482.00834, std: 1420.36432, params: {'normalize': True, 'alpha': 100.0, 'fit_intercept': True}, mean: -1747.18651, std: 1104.02367, params: {'normalize': False, 'alpha': 100.0, 'fit_intercept': True}, mean: -1745.43956, std: 1135.17580, params: {'normalize': True, 'alpha': 100.0, 'fit_intercept': False}, mean: -1745.43956, std: 1135.17580, params: {'normalize': False, 'alpha': 100.0, 'fit_intercept': False}, mean: -2498.67135, std: 1423.96638, params: {'normalize': True, 'alpha': 1000.0, 'fit_intercept': True}, mean: -2011.73199, std: 1280.11363, params: {'normalize': False, 'alpha': 1000.0, 'fit_intercept': True}, mean: -2006.68737, std: 1374.41496, params: {'normalize': True, 'alpha': 1000.0, 'fit_intercept': False}, mean: -2006.68737, std: 1374.41496, params: {'normalize': False, 'alpha': 1000.0, 'fit_intercept': False}, mean: -2500.37228, std: 1424.33129, params: {'normalize': True, 'alpha': 10000.0, 'fit_intercept': True}, mean: -2390.41585, std: 1396.53340, params: {'normalize': False, 'alpha': 10000.0, 'fit_intercept': True}, mean: -2497.15613, std: 1803.65421, params: {'normalize': True, 'alpha': 10000.0, 'fit_intercept': False}, mean: -2497.15613, std: 1803.65421, params: {'normalize': False, 'alpha': 10000.0, 'fit_intercept': False}, mean: -2500.54272, std: 1424.36783, params: {'normalize': True, 'alpha': 100000.0, 'fit_intercept': True}, mean: -2486.56042, std: 1421.04475, params: {'normalize': False, 'alpha': 100000.0, 'fit_intercept': True}, mean: -3320.96052, std: 2391.52296, params: {'normalize': True, 'alpha': 100000.0, 'fit_intercept': False}, mean: -3320.96052, std: 2391.52296, params: {'normalize': False, 'alpha': 100000.0, 'fit_intercept': False}, mean: -2500.55977, std: 1424.37148, params: {'normalize': True, 'alpha': 1000000.0, 'fit_intercept': True}, mean: -2499.11274, std: 1424.03141, params: {'normalize': False, 'alpha': 1000000.0, 'fit_intercept': True}, mean: -3655.85511, std: 2559.18637, params: {'normalize': True, 'alpha': 1000000.0, 'fit_intercept': False}, mean: -3655.85511, std: 2559.18637, params: {'normalize': False, 'alpha': 1000000.0, 'fit_intercept': False}, mean: -2500.56148, std: 1424.37185, params: {'normalize': True, 'alpha': 10000000.0, 'fit_intercept': True}, mean: -2500.41625, std: 1424.33776, params: {'normalize': False, 'alpha': 10000000.0, 'fit_intercept': True}, mean: -3698.74135, std: 2579.10865, params: {'normalize': True, 'alpha': 10000000.0, 'fit_intercept': False}, mean: -3698.74135, std: 2579.10865, params: {'normalize': False, 'alpha': 10000000.0, 'fit_intercept': False}, mean: -2500.56165, std: 1424.37189, params: {'normalize': True, 'alpha': 100000000.0, 'fit_intercept': True}, mean: -2500.54712, std: 1424.36848, params: {'normalize': False, 'alpha': 100000000.0, 'fit_intercept': True}, mean: -3703.14775, std: 2581.13832, params: {'normalize': True, 'alpha': 100000000.0, 'fit_intercept': False}, mean: -3703.14775, std: 2581.13832, params: {'normalize': False, 'alpha': 100000000.0, 'fit_intercept': False}, mean: -2500.56167, std: 1424.37189, params: {'normalize': True, 'alpha': 1000000000.0, 'fit_intercept': True}, mean: -2500.56021, std: 1424.37155, params: {'normalize': False, 'alpha': 1000000000.0, 'fit_intercept': True}, mean: -3703.58959, std: 2581.34167, params: {'normalize': True, 'alpha': 1000000000.0, 'fit_intercept': False}, mean: -3703.58959, std: 2581.34167, params: {'normalize': False, 'alpha': 1000000000.0, 'fit_intercept': False}, mean: -2500.56167, std: 1424.37189, params: {'normalize': True, 'alpha': 10000000000.0, 'fit_intercept': True}, mean: -2500.56152, std: 1424.37186, params: {'normalize': False, 'alpha': 10000000000.0, 'fit_intercept': True}, mean: -3703.63379, std: 2581.36201, params: {'normalize': True, 'alpha': 10000000000.0, 'fit_intercept': False}, mean: -3703.63379, std: 2581.36201, params: {'normalize': False, 'alpha': 10000000000.0, 'fit_intercept': False}]\n"
     ]
    }
   ],
   "source": [
    "print gs.grid_scores_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Independent Practice: Bike data revisited\n",
    "\n",
    "There are tons of ways to approach a regression problem. The regularization techniques appended to ordinary least squares optimizes the size of coefficients to best account for error. Gradient Descent also introduces learning rate (how aggressively do we solve the problem), epsilon (at what point do we say the error margin is acceptable), and iterations (when should we stop no matter what?)\n",
    "\n",
    "For this deliverable, our goals are to:\n",
    "\n",
    "- implement the gradient descent/ridge/regression/OLS approach to our bike-share modeling problem,\n",
    "- demonstrate the grid_search module!\n",
    "\n",
    "While exploring the Gradient Descent regressor object, you'll build a grid search using the stochastic gradient descent estimator for the bike-share data set. Continue with either the model you evaluated last class or the simpler one from today. In particular, be sure to implement the \"param_grid\" in the grid search to get answers for the following questions:\n",
    "\n",
    "- With a set of alpha values between 10^-10 and 10^-1, how does the mean squared error change?\n",
    "- Based on the data, we know when to properly use l1 vs l2 regularization. By using a grid search with l1_ratios between 0 and 1 (increasing every 0.05), does that statement hold true? If not, did gradient descent have enough iterations?\n",
    "- How do these results change when you alter the learning rate (eta0)?\n",
    "\n",
    "**Bonus**: Can you see the advantages and disadvantages of using gradient descent after finishing this exercise?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starter Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST ESTIMATOR\n",
      "1690.56298346\n",
      "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
      "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
      "       loss='squared_loss', n_iter=5, penalty='l2', power_t=0.25,\n",
      "       random_state=None, shuffle=True, verbose=0, warm_start=False)\n",
      "ALL ESTIMATORS\n",
      "[mean: -1690.56298, std: 121.65804, params: {}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "params = {} # put your gradient descent parameters here\n",
    "gs = grid_search.GridSearchCV(\n",
    "    estimator=linear_model.SGDRegressor(),\n",
    "    cv=cross_validation.KFold(len(modeldata), n_folds=5, shuffle=True),\n",
    "    param_grid=params,\n",
    "    scoring='mean_squared_error',\n",
    "    )\n",
    "\n",
    "gs.fit(modeldata, y)\n",
    "\n",
    "print 'BEST ESTIMATOR'\n",
    "print -gs.best_score_\n",
    "print gs.best_estimator_\n",
    "print 'ALL ESTIMATORS'\n",
    "print gs.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## go for it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
       "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
       "       loss='squared_loss', n_iter=5, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus : Try to compare SGD Regressor with linear regression in terms of MSE and R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
